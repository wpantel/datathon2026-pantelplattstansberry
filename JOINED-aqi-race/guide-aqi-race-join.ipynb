{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Integration: AQI vs. Racial Demographics\n",
                "\n",
                "### Objective\n",
                "This notebook documents the process of joining air quality data with racial demographic data across US counties. This integrated dataset enables analysis of environmental justice by examining whether certain racial groups are disproportionately exposed to higher levels of air pollution.\n",
                "\n",
                "### Key Steps:\n",
                "1. **Normalization**: Splitting the combined \"County, State\" field in the race dataset into separate columns and standardizing county names.\n",
                "2. **Merge Operation**: Performing an inner join to combine datasets while ensuring data integrity.\n",
                "3. **Export**: Saving the refined dataset for further analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "# File Paths (adjusted to be run from project root or inside the folder)\n",
                "if os.path.exists('aqi-datasets'):\n",
                "    AQI_DATA_PATH = 'aqi-datasets/ml_target_dataset.csv'\n",
                "    RACE_DATA_PATH = 'race-by-county/cleaned_race_by_county.csv'\n",
                "else:\n",
                "    AQI_DATA_PATH = '../aqi-datasets/ml_target_dataset.csv'\n",
                "    RACE_DATA_PATH = '../race-by-county/cleaned_race_by_county.csv'\n",
                "\n",
                "OUTPUT_PATH = 'aqi_race_joined.csv'\n",
                "\n",
                "def load_data():\n",
                "    aqi_df = pd.read_csv(AQI_DATA_PATH)\n",
                "    race_df = pd.read_csv(RACE_DATA_PATH)\n",
                "    return aqi_df, race_df\n",
                "\n",
                "aqi_df, race_df = load_data()\n",
                "\n",
                "print(f\"AQI Dataset: {aqi_df.shape[0]} rows\")\n",
                "print(f\"Race Dataset: {race_df.shape[0]} rows\")\n",
                "aqi_df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Normalization\n",
                "\n",
                "The racial demographic dataset stores location information as a single string (e.g., `\"Autauga County, Alabama\"`). We need to split this into separate `State` and `County` columns to match the structure of the AQI dataset.\n",
                "\n",
                "Additionally, we must remove suffixes like \" County\", \" Borough\", etc., to ensure that \"Baldwin\" in one dataset matches \"Baldwin County\" in the other."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_race_data(df):\n",
                "    # Split 'County_Area' into County and State\n",
                "    split_data = df['County_Area'].str.split(', ', expand=True)\n",
                "    df['County'] = split_data[0]\n",
                "    df['State'] = split_data[1]\n",
                "    \n",
                "    # Suffixes to remove to ensure consistency with AQI data format\n",
                "    suffixes = [\n",
                "        ' County', ' Borough', ' Census Area', ' Municipality', \n",
                "        ' City and Borough', ' Parish', ' City', ' City and County'\n",
                "    ]\n",
                "    \n",
                "    # Clean County Names\n",
                "    for suffix in suffixes:\n",
                "        df['County'] = df['County'].str.replace(suffix, '', regex=False)\n",
                "    \n",
                "    # Strip whitespace for precision\n",
                "    df['County'] = df['County'].str.strip()\n",
                "    df['State'] = df['State'].str.strip()\n",
                "    \n",
                "    return df\n",
                "\n",
                "race_df_cleaned = normalize_race_data(race_df.copy())\n",
                "print(\"Normalized Race Data Sample:\")\n",
                "race_df_cleaned[['County', 'State', '% White alone', '% Black or African American alone']].head(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Inner Join\n",
                "\n",
                "We perform an inner join on `State` and `County`. This operation combines the datasets only where record matches exist in both, which ensures the resulting analysis is based on complete information."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform inner join\n",
                "joined_df = pd.merge(\n",
                "    aqi_df, \n",
                "    race_df_cleaned.drop(columns=['County_Area', 'GEO_ID']), # Drop unnecessary columns\n",
                "    on=['State', 'County'], \n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "print(f\"Success! Joined dataset has {joined_df.shape[0]} rows.\")\n",
                "joined_df.head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Export Success\n",
                "\n",
                "The final step is to save the integrated dataset as a CSV file for use in our models and visualizations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joined_df.to_csv(OUTPUT_PATH, index=False)\n",
                "print(f\"Dataset exported successfully to {OUTPUT_PATH}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}